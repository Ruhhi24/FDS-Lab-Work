{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ag6DGHHGDeHb","OHyk1dUUDprb"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poCKpUm5W_Yh","outputId":"0332cc0b-6f70-4f78-8eba-1d976bb4096d","executionInfo":{"status":"ok","timestamp":1670087272204,"user_tz":-330,"elapsed":212185,"user":{"displayName":"617_Ruhhi_Adharkar","userId":"11104313637023149008"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/\n","Mounted at /content/gdrive\n"]}],"source":["%cd ..\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["from google.colab import files\n","\n","\n","uploaded = files.upload()"],"metadata":{"id":"UwYYxihATlk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import io\n","\n","df = pd.read_csv(io.BytesIO(uploaded['airline_stats.csv']))\n","print(df)"],"metadata":{"id":"DTgBu1cJVIhy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Unzipping dataset\n","dir=\"/content/gdrive/MyDrive/FDS_PRAC/datasets\"\n","import zipfile\n","zip_ref=zipfile.ZipFile(\"/content/gdrive/MyDrive/FDS_PRAC/datasets.zip\",\"r\")\n","zip_ref.extractall(dir)\n","zip_ref.close()"],"metadata":{"id":"WRsJrT-6ZbT2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#importing numpy library\n","import numpy\n","#importing pandas library\n","import pandas as pd\n","#Defining path of csv file\n","location=\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/smallgradesh.csv\"\n","open(location).read()"],"metadata":{"id":"zK8Elh5udDv7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Displaying data of .csv file without header\n","df=pd.read_csv(location,header=None)\n","df"],"metadata":{"id":"lTr0u5SFBq9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Display first five lines of data\n","df.head()"],"metadata":{"id":"cqeijOccBv16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading data from CSV file and adding header\n","location=\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/smallgradesh.csv\"\n","\n","#To add headers as we load\n","df=pd.read_csv(location,names=['Names','Grades'])\n","#To add headers to dataframe\n","df.columns=['Names','Grades']\n","df.head()"],"metadata":{"id":"5gP-6Q-2CIq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Exporting a dataset to CSV\n","import pandas as pd\n","names=['Bob','Jessica','Mary','John','Mel']\n","grades=[76,95,77,78,99]\n","GradeList=zip(names,grades)\n","df=pd.DataFrame(data=GradeList,columns=['Names','Grades'])\n","df.to_csv('studentgrades.csv',index=False,header=False)\n","df"],"metadata":{"id":"QwCbhv8gCJFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","names=['Bob','Jessica','Mary','John','Mel']\n","grades=[76,95,77,78,99]\n","bsdeg=[1,1,0,0,1]\n","msdeg=[2,1,0,0,0]\n","phd=[0,1,0,0,0]\n","GradeList=zip(names,grades,bsdeg,msdeg,phd)\n","df=pd.DataFrame(data=GradeList,columns=['Names','Grades','BS','MS','Phd'])\n","df.to_csv('studentgrades.csv',index=False,header=False)\n","df"],"metadata":{"id":"jO1ZobGVCJRl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","csvdata=pd.read_csv(\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/gradedata.csv\")\n","resultexcel=pd.ExcelWriter(\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/gradedata.xlsx\")\n","csvdata.to_excel(resultexcel)\n","resultexcel.save()\n","exceldata=pd.read_excel(\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/gradedata.xlsx\")\n","exceldata"],"metadata":{"id":"FESkPNaECJbL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","location=\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/gradedata.xlsx\"\n","df= pd.read_excel(location,index_col=0)\n","df\n","#Changing column name\n","df.columns=['first','last','sex','age','exer','hrs','grd','addr']\n","df.head()"],"metadata":{"id":"CtwMLJMACJok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install xlsxwriter"],"metadata":{"id":"QgKJdnP4CJyU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","names=['Bob','Jessica','Mary','John','Mel']\n","grades=[76,95,77,78,99]\n","GradeList=zip(names,grades)\n","df=pd.DataFrame(data=GradeList,columns=['Names','Grades'])\n","writer=pd.ExcelWriter('dataframe.xlsx',engine='xlsxwriter')\n","df.to_excel(writer,sheet_name='Sheet1')\n","writer.save()\n","Location=\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/gradedata.xlsx\"\n","df=pd.read_excel(Location)\n","df.head()"],"metadata":{"id":"IpXf-fvLCJ65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sqlite3\n","from sqlite3 import Error\n","\n","\n","def create_connection(db_file):\n","    \"\"\" create a database connection to a SQLite database \"\"\"\n","    conn = None\n","    try:\n","        conn = sqlite3.connect(db_file)\n","        print(sqlite3.version)\n","    except Error as e:\n","        print(e)\n","    finally:\n","        if conn:\n","            conn.close()\n","\n","\n","if __name__ == '__main__':\n","    create_connection(r\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/gradedata.db\")"],"metadata":{"id":"TKUMLndKwY7H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sqlite3 as lite\n","conn=lite.connect('/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/gradedata.db')\n","c=conn.cursor()\n","db_filename=r'/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/gradedata.db'\n","con=lite.connect(db_filename)\n","df.to_sql('test',\n","          con,\n","          schema=None,\n","          if_exists='replace',\n","          index=True,\n","          index_label=None,\n","          chunksize=None,\n","          dtype=None\n","          )\n","con.close()"],"metadata":{"id":"bkgs_I_Aw7xP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["names=['Bob','Jessica','Mary','John','Mel']\n","grades=[76,95,77,78,99]\n","GradeList=zip(names,grades)\n","df=pd.DataFrame(data=GradeList,columns=['names','Grades'])\n","df"],"metadata":{"id":"x4AD1P3DyoGX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sqlalchemy import create_engine\n","#Connect to sqlite db\n","db_file=r'content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/gradedata.xlsx'\n","engine=create_engine(\"sqlite:///{}\".format(db_file))\n","sql='SELECT * from test where Grades in (76,77,78)'\n","sales_data_df = pd.read_sql(sql,engine)\n","sales_data_df"],"metadata":{"id":"CJ567-d5CKEK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sqlite3 as lite\n","db_filename=r'mydb.db'\n","con=lite.connect(db_filename)\n","df.to_sql('mytable',\n","          con,\n","          schema=None,\n","          if_exists='replace',\n","          index=True,\n","          index_label=None,\n","          chunksize=None,\n","          dtype=None\n","          )\n","con.close()"],"metadata":{"id":"ezSXQDCICkLx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pandas import DataFrame\n","Cars={'Brand':['Honda Civic','Toyota Corolla','Ford Focus','Audi A4'],\n","      'Price':[22000,25000,27000,35000]\n","      }\n","df=DataFrame(Cars,columns=['Brand','Price'])\n","print(df)"],"metadata":{"id":"u5xZtpy2CkYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sqlite3"],"metadata":{"id":"fFs_n8JlCkh0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conn=sqlite3.connect('TestDB1.db')\n","c=conn.cursor()"],"metadata":{"id":"ravdlqmWCkuG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["c.execute('CREATE TABLE CARS (Brand text, Price number)')\n","conn.commit()"],"metadata":{"id":"75V4bly_Ck5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_sql('CARS',conn,if_exists='replace',index=False)"],"metadata":{"id":"p8qgucNoClDq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conn=sqlite3.connect('TestDB2.db')\n","c=conn.cursor()\n","c.execute('CREATE TABLE CARS (Brand text, Price number)')\n","conn.commit()"],"metadata":{"id":"xDYZ82G3ClM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Cars={'Brand':['Honda Civic','Toyota Corolla','Ford Focus','Audi A4'],\n","      'Price':[22000,25000,27000,35000]\n","      }\n","df=DataFrame(Cars,columns=['Brand','Price'])\n","print(df)"],"metadata":{"id":"0GfcDsIBClXv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_sql('CARS',conn,if_exists='replace',index=False)"],"metadata":{"id":"mXOmk7bGClgO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["c.execute('''\n","SELECT Brand,max(Price) from CARS\n","''')"],"metadata":{"id":"6pn8QTAeC5C6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=DataFrame(c.fetchall(),columns=['Brand','Price'])\n","df"],"metadata":{"id":"TRkkxGotC5Lm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import pandas as pd\n","import os\n","import sqlite3 as lite\n","from sqlalchemy import create_engine\n"," \n","EmpId=[\"E101\",\"E102\",\"E103\",\"E104\"]\n","FName=[\"Shweta\",\"Manisha\",\"Madhu\",\"Anita\"]\n","LName=[\"Subnis\",\"Perdesi\",\"Mali\",\"Rai\"]\n","Designation=[\"ProjectEngineer\",\"Tester\",\"SrSoftwareEngineer\",\"WebDeveloper\"]\n","Basic_Salary=[40000,50000,60000,70000]\n"," \n","Empdata = zip(EmpId,FName,LName,Designation,Basic_Salary)\n","df = pd.DataFrame(data =Empdata, columns=['EmpId','FName','LName','Designation','Basic_Salary'])\n","df.to_csv('studentgrades.csv',index=False,header=False)\n"," \n"," \n"," \n","df\n"," \n","df1=df.to_csv('employeedata.csv',index=False,header=True)\n"," \n","df2=df.to_excel('employeedata2.xlsx',index=False,header=True)\n"," \n","db_filename = r'employee.db'\n","con = lite.connect(db_filename)\n","df.to_sql('employee',\n","con,\n","schema=None,\n","if_exists='replace',\n","index=True,\n","index_label=None,\n","chunksize=None,\n","dtype=None)\n","con.close()\n"," \n","dfcsv=pd.read_csv(\"employeedata.csv\")\n"," \n","dfcsv\n"," \n","dfex=pd.read_excel(\"employeedata2.xlsx\")\n","dfex\n"," \n","db_file = r'employee.db'\n","engine = create_engine(r\"sqlite:///{}\" .format(db_file))\n","sql = 'SELECT * from employee '\n","'where Basic_Salary in (40000,50000,60000,70000)'\n","empdf = pd.read_sql(sql, engine)\n","empdf"],"metadata":{"id":"qIAc5i-xC5UJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd \n","import os\n","import sqlite3 as lite\n","from sqlalchemy import create_engine\n","\n","studentId=[\"rj101\",\"rj150\",\"rj134\",\"rj70\"]\n","SName=[\"Saurabh\",\"Giftson\",\"Vikas\",\"Radha\"]\n","LName=[\"Chavan\",\"Paul\",\"Bisoi\",\"Rai\"]\n","Department=[\"Bms\",\"Bcom\",\"BscCS\",\"BScIT\"]\n","Email=[\"100rabh@gmail.com\",\"gift01@gmail.com\",\"vik21@gmail.com\",\"rad01@gmail.com\"]\n","\n","studata = zip(studentId,SName,LName,Department,Email)\n","df = pd.DataFrame(data =studata, columns=['StudentId','SName','LName','Department','Email'])\n","df.to_csv('studentdata.csv',index=False,header=False)\n","\n","df\n","df1=df.to_csv('studentdata.csv',index=False,header=True)\n"," \n","df2=df.to_excel('studentdata2.xlsx',index=False,header=True)\n"," \n","db_filename = r'studentdata.db'\n","con = lite.connect(db_filename)\n","df.to_sql('student',\n","con,\n","schema=None,\n","if_exists='replace',\n","index=True,\n","index_label=None,\n","chunksize=None,\n","dtype=None)\n","con.close()\n","\n","dfcsv=pd.read_csv(\"studentdata.csv\")\n","dfcsv\n","\n","\n","dfex=pd.read_excel(\"studentdata2.xlsx\")\n","dfex\n","\n","db_file = r'studentdata.db'\n","engine = create_engine(r\"sqlite:///{}\" .format(db_file))\n","sql = 'SELECT * from student '\n","\n","\n","studf = pd.read_sql(sql, engine)\n","studf"],"metadata":{"id":"gWLZxiyxC5cS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import pandas as pd \n","import os\n","import sqlite3 as lite\n","from sqlalchemy import create_engine\n","\n","sales_Representative=[\"sara\",\"farahan\",\"patrick\",\"francheska\",\"Henry\",\"preson\"]\n","Location=[\"New_York\",\"Oregon\",\"New_Jersy\",\"New_York\",\"Washington\",\"Oregon\"]\n","Region=[\"East\",\"west\",\"East\",\"East\",\"West\",\"East\"]\n","Customer=[\"Justin\",\"Roy\",\"Aian\",\"Franklin\",\"Danie\",\"Phyllis\"]\n","Item=[\"Watch\",\"Mobile\",\"Stationary\",\"Jeans\",\"Mobile\",\"TV\"]\n","Quantity=[2,1,15,2,1]\n","Price=[1000,25000,500,5750,10000,50000]\n","\n","saledata = zip(sales_Representative,Location,Region,Customer,Item,Quantity,Price)\n","df = pd.DataFrame(data =saledata, columns=['sales_Representative','Location','Region','Customer','Item','Quantity','Price'])\n","df.to_csv('salestdata.csv',index=False,header=False)\n","\n","\n","df\n","df1=df.to_csv('sale1tdata.csv',index=False,header=True)\n"," \n","df2=df.to_excel('sale2.xlsx',index=False,header=True)\n"," \n","db_filename = r'salesmandata.db'\n","con = lite.connect(db_filename)\n","df.to_sql('salesman',\n","con,\n","schema=None,\n","if_exists='replace',\n","index=False,\n","index_label=None,\n","chunksize=None,\n","dtype=None)\n","con.close()\n","\n","dfcsv=pd.read_csv(\"sale1tdata.csv\")\n","dfcsv\n","\n","\n","dfex=pd.read_excel(\"sale2.xlsx\")\n","dfex\n","\n","db_file = r'salesmandata.db'\n","engine = create_engine(r\"sqlite:///{}\" .format(db_file))\n","sql = 'SELECT * from salesman '\n","\n","\n","saledf = pd.read_sql(sql, engine)\n","saledf"],"metadata":{"id":"DsnYjCzkC5kt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd \n","import os\n","import sqlite3 as lite\n","from sqlalchemy import create_engine\n","  \n","# list of name, degree, score \n","nme = [\"aparna\", \"pankaj\", \"sudhir\", \"Geeku\"] \n","deg = [\"MBA\", \"BCA\", \"M.Tech\", \"MBA\"] \n","scr = [90, 40, 80, 98] \n","  \n","# dictionary of lists  \n","dict = {'name': nme, 'degree': deg, 'score': scr}  \n","    \n","df = pd.DataFrame(dict) \n","    \n","df  \n","df.to_csv('scoredata.csv',index=False,header=False)\n","\n","\n","df\n","df1=df.to_csv('scoredata1.csv',index=False,header=True)\n"," \n","df2=df.to_excel('scoredata2.xlsx',index=False,header=True)\n"," \n","db_filename = r'score.db'\n","con = lite.connect(db_filename)\n","df.to_sql('scoretable',\n","con,\n","schema=None,\n","if_exists='replace',\n","index=False,\n","index_label=None,\n","chunksize=None,\n","dtype=None)\n","con.close()\n","\n","dfcsv=pd.read_csv(\"scoredata1.csv\")\n","dfcsv\n","\n","\n","dfex=pd.read_excel(\"scoredata2.xlsx\")\n","dfex\n","\n","db_file = r'score.db'\n","engine = create_engine(r\"sqlite:///{}\" .format(db_file))\n","sql = 'SELECT * from scoretable where score is 90'\n","\n","\n","scoredf = pd.read_sql(sql, engine)\n","scoredf"],"metadata":{"id":"BwT_fr40C5uI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd \n","import os\n","import sqlite3 as lite\n","from sqlalchemy import create_engine\n","\n","# Create two lists in Python\n","education = [\"Bachelor's\", \"Less than Bachelor's\",\n","             \"Master's\",\"PhD\",\"Professional\"]\n","salary = [110000,105000,126000,144200,96000]\n","\n","# create a dictionary using lists\n","a_dict = {\"Education\":education,\n","                  \"Salary\":salary}\n","\n","# Create a data frame using the dictionary\n","df = pd.DataFrame(a_dict)\n","df\n","\n","df.to_csv('salarydata.csv',index=False,header=False)\n","\n","\n","df\n","df1=df.to_csv('salarydata1.csv',index=False,header=True)\n"," \n","df2=df.to_excel('salarydata2.xlsx',index=False,header=True)\n"," \n","db_filename = r'salary.db'\n","con = lite.connect(db_filename)\n","df.to_sql('salarytable',\n","con,\n","schema=None,\n","if_exists='replace',\n","index=False,\n","index_label=None,\n","chunksize=None,\n","dtype=None)\n","con.close()\n","\n","dfcsv=pd.read_csv(\"salarydata1.csv\")\n","dfcsv\n","\n","\n","dfex=pd.read_excel(\"salarydata2.xlsx\")\n","dfex\n","\n","db_file = r'salary.db'\n","engine = create_engine(r\"sqlite:///{}\" .format(db_file))\n","sql = 'SELECT * from salarytable where salary is 144200'\n","\n","\n","scoredf = pd.read_sql(sql, engine)\n","scoredf"],"metadata":{"id":"iV7JdaV7C526"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Data Preprocessing: Data preprocessing is an important step in the data mining process. The phrase \"garbage in, garbage out\" is particularly applicable to data mining and machine learning projects. Data-gathering methods are often loosely controlled, resulting in out-of-range values (e.g., Income: âˆ’100), impossible data combinations (e.g., Sex: Male, Pregnant: Yes), and missing values, etc. Analyzing data that has not been carefully screened for such problems can produce misleading results. Thus, the representation and quality of data is first and foremost before running any analysis.[1] Often, data preprocessing is the most important phase of a machine learning project, especially in computational biology.**\n","### **If there is much irrelevant and redundant information present or noisy and unreliable data, then knowledge discovery during the training phase is more difficult. Data preparation and filtering steps can take considerable amount of processing time. Data preprocessing includes cleaning, Instance selection, normalization, transformation, feature extraction and selection, etc. The product of data preprocessing is the final training set.**\n","\n","### **Data Transformation: Data transformation is the process of converting data from one format or structure into another format or structure. It is a fundamental aspect of most data integration and data management tasks such as data wrangling, data warehousing, data integration and application integration.**\n","### **Data transformation can be simple or complex based on the required changes to the data between the source (initial) data and the target (final) data. Data transformation is typically performed via a mixture of manual and automated steps. Tools and technologies used for data transformation can vary widely based on the format, structure, complexity, and volume of the data being transformed.**\n"],"metadata":{"id":"ag6DGHHGDeHb"}},{"cell_type":"markdown","source":["# **Data Preprocessing (Data Preparation and Data Transformations)**\n","\n","1.   Missing Values\n","2.   Group By \n","3.   Merge\n","4.   Transform\n","5.   Apply\n","\n","\n"],"metadata":{"id":"OHyk1dUUDprb"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd"],"metadata":{"id":"MFuVySs8C5_u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["state=pd.read_csv(\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/state (1).csv\")\n","state.head()"],"metadata":{"id":"r3OxcOM3C6IU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#apply\n","def some_func(x):\n","  return x*2\n","state.apply(some_func) #update each entry of dataframe without any loop\n","state.apply(lambda n: n*2) #lambda also works the same"],"metadata":{"id":"huVTeJcPC6QJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#transform\n","state.transform(func = lambda x : x * 10)"],"metadata":{"id":"9OjtaPftC6e4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#usinggroupby\n","mean_purchase =state.groupby('Abbreviation')[\"Murder.Rate\"].mean().rename(\"User_mean\").reset_index() \n","print(mean_purchase)"],"metadata":{"id":"8BOuNzRMC6nJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#usinmerge\n","mean_purchase =state.groupby('Abbreviation')[\"Murder.Rate\"].mean().rename(\"User_mean\").reset_index() \n","print(mean_purchase)\n","mer=state.merge(mean_purchase)"],"metadata":{"id":"X0CDr7qzD609"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mer"],"metadata":{"id":"_w22-D_hD7BD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking for missing values\n","print(state.isnull().sum())"],"metadata":{"id":"UTDr0-OwD7Jd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","cols=['col0', 'col1', 'col2', 'col3', 'col4']\n","rows=['row0', 'row1', 'row2', 'row3', 'row4']\n","data=np.random.randint(0, 100, size=(5,5))\n","df=pd.DataFrame(data, columns=cols, index=rows)\n","df.head()"],"metadata":{"id":"mkImasmlD7RJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.iloc[4, 2]"],"metadata":{"id":"l-j6MAYdD7Yg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#use all() method to select columns that don't have zero values\n","df.loc[:, df.all()]"],"metadata":{"id":"JinegeStD7f1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#display column that have atleast one non zero value\n","df.loc[:, df.any()]"],"metadata":{"id":"S5beh1XND7m0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#select columns with any nan\n","df.loc[:,df.isnull().any()]"],"metadata":{"id":"lgzEaSneD7tI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#select column withou nan\n","df.loc[:, df.notnull().all()]"],"metadata":{"id":"4tZmqO9ND70Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dropna(how=\"all\", axis=1) #if all the values in columns are nan it will be dropped"],"metadata":{"id":"iMoQinwPD76-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dropna(how=\"any\", axis=1) #if all the values in row are nan it will be dropped"],"metadata":{"id":"KcLTE2GnD8CT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#filling mean value at the place of nan value\n","df.fillna(df.mean())"],"metadata":{"id":"VdN_7Yp_Eb5X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def some_func(x):\n","  return x*2\n","df.apply(some_func) #update each entry of dataframe without any loop\n","df.apply(lambda n: n*2) #lambda also works the same"],"metadata":{"id":"e3dW1wblEcDT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#these function do not return the transformation so we have to store it explicitly\n","df['new_col']=df['col4'].apply(lambda n: n*2)\n","df.head()"],"metadata":{"id":"yca9mUzwEcNh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Transforming function in Python\n","import pandas as pd\n","import numpy as np\n","#creating a dataframe\n","df=pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['a', 'b', 'c'])\n","df"],"metadata":{"id":"Gbd46ytFEcWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#applying the transform function\n","df.transform(func = lambda x : x * 10)"],"metadata":{"id":"x8qQuvxwEcgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Demonstrate transfomr function using pandas in python\n","import pandas as pd\n","import numpy as np\n","import random\n","data = pd.DataFrame({\n","    'C' : [random.choice(('a','b','c')) for i in range(1000000)],\n","    'A' : [random.randint(1,10) for i in range(1000000)],\n","    'B' : [random.randint(1,10) for i in range(1000000)]\n","\n","})\n","data"],"metadata":{"id":"Tat5dSHxEco2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#use the merge procedure\n","data.groupby('C')[\"A\"].mean()\n","mean =data.groupby('C')[\"A\"].mean().rename(\"N\").reset_index()\n","df_1 = data.merge(mean)"],"metadata":{"id":"a2Jrf5LOEcv8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['N3'] = data.groupby(['C'])['A'].transform('mean')"],"metadata":{"id":"c8RoUixvEc20"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#with apply() function\n","\n","df['d'] = df.apply(lambda row: row.a + row.b + row.c, axis=1)"],"metadata":{"id":"MxpeZ6IyEc9u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","Airline=pd.read_csv(\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/airline_stats.csv\")\n","Airline.head()"],"metadata":{"id":"dzYAS_CiEdEL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cheaking missing values\n","print(Airline.isnull().sum())"],"metadata":{"id":"RPPNuYssExnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Airline.fillna(Airline.mean(), inplace=True)\n","Airline.isnull().sum()"],"metadata":{"id":"f5b-vKEqExvj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_purchase =Airline.groupby('pct_atc_delay')[\"pct_weather_delay\"].mean().rename(\"User\").reset_index() \n","print(mean_purchase)"],"metadata":{"id":"FdtLEzghEx2m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_purchase =Airline.groupby('pct_atc_delay')[\"pct_weather_delay\"].mean().rename(\"User\").reset_index() \n","print(mean_purchase)\n","df = Airline.merge(mean_purchase)\n","df"],"metadata":{"id":"omaBX_ZuEx9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#applying the transform function\n","Airline.transform( lambda x : x * 10 )\n"],"metadata":{"id":"yqYwMjIwEyC0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#applying the apply function\n","Airline.apply(lambda n: n *2,axis=1)"],"metadata":{"id":"_-cQPuSLEyJc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","state=pd.read_csv(\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/County_Zhvi_AllHomes.csv\")\n","state.head()"],"metadata":{"id":"_0cssQMXEyP2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(state.isnull().sum())"],"metadata":{"id":"gk8a7_vjEyWW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["state.fillna(state.mean,inplace=True)"],"metadata":{"id":"D3iKIi-mEycH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(state.isnull().sum())"],"metadata":{"id":"GusQ5tXTEyh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_county =state.groupby('StateCodeFIPS')[\"MunicipalCodeFIPS\"].mean().rename(\"User_mean\").reset_index() \n","print(mean_county)"],"metadata":{"id":"DXnmhP8tEytE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#applying the transform function\n","print(loan.transform(lambda x : x * 10))\n","\n","#applying the apply function\n","#state.apply(lambda n:n*2,axis=1)"],"metadata":{"id":"-7ZiLDM5FH-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_county =state.groupby('StateCodeFIPS')[\"MunicipalCodeFIPS\"].mean().rename(\"User_mean\").reset_index() \n","print(mean_county)\n","Ma=state.merge(mean_county)"],"metadata":{"id":"L2IQgAtyFIHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","loan=pd.read_csv(\"/content/gdrive/MyDrive/FDS_PRAC/datasets/FDSJOURNAL_DATASETS/loan_data.csv\")\n","loan.head()"],"metadata":{"id":"LTRk5GGVFIUh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(loan.isnull().sum())"],"metadata":{"id":"9LCcrqN8FIaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_county =loan.groupby(\"loan_amnt\")[\"dti\"].mean().rename(\"dti1\").reset_index() \n","print(mean_county)"],"metadata":{"id":"0OkJO9q7FIel"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#applying the transform function\n","print(loan.transform(lambda x : x * 10))"],"metadata":{"id":"z8yshHXPFIi3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#applying the apply function\n","print(loan.apply(lambda n:n*2,axis=1))"],"metadata":{"id":"IO50czLhFInO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_county =loan.groupby('annual_inc')[\"dti\"].mean().rename(\"dti1\").reset_index() \n","print(mean_county)\n","mer=loan.merge(mean_county)"],"metadata":{"id":"iZWtIiakFIrR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mer"],"metadata":{"id":"kRR-2Xk_FIvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Python program to merge \n","# dataframes using Panda \n","  \n","# Dataframe created \n","left = pd.DataFrame({'Key': ['K0', 'K1', 'K2', 'K3'], \n","                    'A': ['A0', 'A1', 'A2', 'A3'], \n","                    'B': ['B0', 'B1', 'B2', 'B3']}) \n","  \n","right = pd.DataFrame({'Key': ['K0', 'K1', 'K2', 'K3'], \n","                      'C': ['C0', 'C1', 'C2', 'C3'], \n","                      'D': ['D0', 'D1', 'D2', 'D3']}) \n","                        \n","# Merging the dataframes                       \n","pd.merge(left, right, how ='inner', on ='Key')"],"metadata":{"id":"gHGSEqYZFI48"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","left = pd.DataFrame({\n","   'id':[1,2,3,4,5],\n","   'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n","   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n","right = pd.DataFrame({\n","\t'id':[1,2,3,4,5],\n","   'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n","   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n","print(pd.merge(left,right,on='id'))"],"metadata":{"id":"qh8ZFXvPFJGh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n","                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n","df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n","                    'hire_date': [2004, 2008, 2012, 2014]})\n","print(df1)\n","print(df2)\n","\n","df3 = pd.merge(df1, df2)\n","df3"],"metadata":{"id":"J_HBAfNpFJQH"},"execution_count":null,"outputs":[]}]}